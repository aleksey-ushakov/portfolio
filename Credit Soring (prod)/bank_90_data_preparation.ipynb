{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ИМПОРТ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from shutil import copyfile\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dill as pickle #более мощная библиотека позволяющая сохранять функции\n",
    "import copy\n",
    "\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **КЛАСС СБОРЩИКА АГРЕГАТОВ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cборщик агрегатов\n",
    "class AggCollector:\n",
    "    \n",
    "    def __init__ (self,\n",
    "                  acct_type_list,    \n",
    "                  period_dict,\n",
    "                  PATH_TO_DATA,\n",
    "                  account_csv_file_name,\n",
    "                  information_csv_file_name,\n",
    "                  name_csv_file_name,\n",
    "                  address_csv_file_name,\n",
    "                  cbrates_csv_file_name):\n",
    "        \n",
    "        \n",
    "        self.acct_type_list = acct_type_list\n",
    "        self.period_dict = period_dict\n",
    "        \n",
    "        # Путь и названия файлов с данными\n",
    "        self.PATH_TO_DATA = PATH_TO_DATA\n",
    "        \n",
    "        self.account_csv_file_name = account_csv_file_name\n",
    "        self.information_csv_file_name = information_csv_file_name\n",
    "        self.name_csv_file_name = name_csv_file_name\n",
    "        self.address_csv_file_name = address_csv_file_name\n",
    "        self.cbrates_csv_file_name = cbrates_csv_file_name\n",
    "        \n",
    "        # Заголовки столбцов таблиц        \n",
    "        self.account_cols = ['ACCT_RTE_CDE', 'ACCT_RTE_DTE', 'ACCT_TYPE', 'AMT_PAST_DUE', 'CLOSED_DT', 'REPORTING_DT',\n",
    "                             'CREDIT_LIMIT', 'CURRENCY_CODE', 'FID', 'MEMBER_CODE', 'OPENED_DT', 'OWNER_INDIC',\n",
    "                             'PAYMT_PAT', 'PAYMT_PAT_START_DT', 'PAYT_DUE_DTE', 'SERIAL_NUM']\n",
    "        \n",
    "        self.name_cols = ['FID', 'FILE_SINCE_DT', 'LAST_UPDATED_DT', 'MIDDLE', 'BIRTH_DT']\n",
    "        self.info_cols = ['SERIAL_NUM', 'FID', 'APP_DATE', 'CREDITOR_TYPE', 'MEMBER_CODE', 'TYPE_FLAG', 'LOAN_TYPE',\n",
    "                          'FLAG_OF_APPROVAL', 'REJECTED_AMT',  'REJ_AMT_CUR', 'REJECTION_DTE', 'REJECTION_REASON']\n",
    "        self.addr_cols = ['FID', 'PROV', 'ADDR_REL_TYP_CDE', 'FILE_SINCE_DT', 'LAST_UPDATED_DT']       \n",
    "        \n",
    "        self.db_names = None\n",
    "        self.db_cbrates = None\n",
    "        self.db_addr = None\n",
    "        self.account_keys = None\n",
    "        self.info_keys = None\n",
    "        \n",
    "        self.df_keys = None\n",
    "        self.df = None\n",
    "        self.df_rejects = None\n",
    "        self.db_account = None\n",
    "        self.db_info = None\n",
    "        \n",
    "        self.df_test = None\n",
    "        self.df_test_FID = None\n",
    "        self.df_test_account = None\n",
    "        self.df_test_info = None\n",
    "        \n",
    "        self.name = None\n",
    "        self.log = ''\n",
    "        \n",
    "\n",
    "    # Функция логирования\n",
    "    def print_log(self, log_str, level=0, timestamp=True):\n",
    "        \n",
    "        if not self.name:\n",
    "            self.name = [name for name in globals() if globals()[name] == self][0]\n",
    "        \n",
    "        now_str = lambda : datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        if timestamp:\n",
    "            log_str = '{:.<70}   {}\\n'.format(level * 4 * ' ' + log_str + '   ', now_str()) \n",
    "        else:\n",
    "            log_str = level * 4 * ' ' + log_str + '\\n'\n",
    "\n",
    "        # Запись в лог экземпляра класса \n",
    "        self.log += log_str\n",
    "        \n",
    "        # Запись в лог файл\n",
    "        with open(self.PATH_TO_DATA + self.name + '.log', 'a', encoding='utf-8') as f:\n",
    "            f.write(log_str)\n",
    "\n",
    "        # Вывод сообещения на экран\n",
    "        print(log_str, end='')\n",
    "        \n",
    "        \n",
    "    # Формирование файлов с агрегатами из сырх данных\n",
    "    def collect(self, periods_to_collect_list='all', check_data_export=False, collect_rejects=False):\n",
    "        self.print_log('РАСЧЕТ АГРЕГАТОВ\\n', level=0, timestamp=False)\n",
    "        self.load_account_keys()\n",
    "        self.laod_info_keys()\n",
    "        self.process_db_addr()\n",
    "        self.process_db_names()\n",
    "        self.process_db_cbrates()\n",
    "        \n",
    "        if periods_to_collect_list=='all':\n",
    "            periods_to_collect_list = list(self.period_dict.keys())\n",
    "        \n",
    "        for period in periods_to_collect_list:\n",
    "            \n",
    "            start_date, finish_date = self.period_dict[period][0], self.period_dict[period][1]\n",
    "            self.print_log('\\nПЕРИОД {} - {}:'.format(start_date, finish_date), level=0, timestamp=False)\n",
    "            \n",
    "            # Предобработка данных\n",
    "            self.get_df_keys(start_date=start_date, finish_date=finish_date, portion=1)\n",
    "            self.process_db_account(start_date, finish_date)\n",
    "            self.process_db_info()\n",
    "            \n",
    "            # Формирование датасета для сбора агрегатов по отказникам (обрезание датасета до размера )\n",
    "            if collect_rejects:\n",
    "                self.keep_rejects_only()\n",
    "            \n",
    "            # Формирование списка тестовых FID\n",
    "            if self.df.shape[0] < 2000:\n",
    "                chek_data_qty = self.df.shape[0]\n",
    "            else: \n",
    "                chek_data_qty = 2000\n",
    "            \n",
    "            self.df_test_FID = self.df.sample(chek_data_qty, replace=False, random_state=42)['FID'].unique()\n",
    "            \n",
    "            # Сбор агрегатов и расчет флагов\n",
    "            self.agg_db_address()\n",
    "            self.agg_db_names()\n",
    "            self.agg_db_info()            \n",
    "            self.agg_db_account()\n",
    "            self.flag_calculation()\n",
    "            \n",
    "            # Экспорт файла с агрегатами            \n",
    "            if collect_rejects:\n",
    "                df_file_name = 'REJECT_AGG_' + period + '.csv'\n",
    "                # Добавление информации об отказах\n",
    "                self.df = pd.merge(self.df,\n",
    "                                   self.df_rejects,\n",
    "                                   how='inner',\n",
    "                                   on=['SERIAL_NUM'],\n",
    "                                   suffixes= ('', '_REJECT'))\n",
    "            else:\n",
    "                df_file_name = 'AGG_' + period + '.csv'\n",
    "            \n",
    "            self.print_log('Выгрузка в файл ' + df_file_name, level=1, timestamp=True)  \n",
    "            self.df.to_csv(self.PATH_TO_DATA + df_file_name, index=False)\n",
    "            self.print_log('Выгрузка в файл завершена', level=1, timestamp=True)\n",
    "            \n",
    "            # Экспорт проверочных данных\n",
    "            if check_data_export:\n",
    "                if collect_rejects:\n",
    "                    check_file_name = 'REJECT_AGG_' + period + '_checkdata.xlsx'\n",
    "                else:\n",
    "                    check_file_name = 'AGG_' + period + '_checkdata.xlsx'\n",
    "                \n",
    "                self.print_log('Сохранение файла ' + check_file_name, level=1, timestamp=True) \n",
    "                \n",
    "                writer = pd.ExcelWriter(self.PATH_TO_DATA + check_file_name)\n",
    "                \n",
    "                self.df_test = self.df[self.df['FID'].isin(self.df_test_FID)]\n",
    "                self.df_test.to_excel(writer, sheet_name='AGG', engine='io.excel.xlsx.writer')                \n",
    "                self.df_test_account.to_excel(writer, sheet_name='ACCOUNT', engine='io.excel.xlsx.writer')\n",
    "                self.df_test_info.to_excel(writer, sheet_name='INFORMATION', engine='io.excel.xlsx.writer')\n",
    "                writer.save()\n",
    "                \n",
    "                self.print_log('Проверочный файл сохранен', level=1, timestamp=True)\n",
    "            \n",
    "            # Удаление всех временных переменных\n",
    "            self.df_keys = None\n",
    "            self.df = None\n",
    "            self.df_rejects = None\n",
    "            self.db_account = None\n",
    "            self.db_info = None\n",
    "            self.df_test = None\n",
    "            self.df_test_FID = None\n",
    "            self.df_test_account = None\n",
    "            self.df_test_info = None\n",
    "    \n",
    "\n",
    "    # Формирование тестового набора данных\n",
    "    def get_sample_data(self, portion=0.05):\n",
    "        \n",
    "        self.print_log('ПОДГОТОВКА СЭМПЛА ДАННЫХ\\n', level=0, timestamp=False)        \n",
    "        \n",
    "        self.load_account_keys()\n",
    "        self.laod_info_keys()\n",
    "        \n",
    "        #Формирование списка сэмпловых FID\n",
    "        periods_to_collect_list = list(self.period_dict.keys())\n",
    "        \n",
    "        self.print_log('\\nСписок целевых FID', level=0, timestamp=False)\n",
    "        \n",
    "        for period in periods_to_collect_list:\n",
    "            start_date, finish_date = self.period_dict[period][0], self.period_dict[period][1]       \n",
    "\n",
    "            \n",
    "            self.get_df_keys(start_date=start_date, finish_date=finish_date, portion=portion)\n",
    "            \n",
    "            if period == periods_to_collect_list[0]:\n",
    "                df_keys = self.df_keys.copy()\n",
    "            else:\n",
    "                df_keys = pd.concat((df_keys, self.df_keys),axis=0)\n",
    "        \n",
    "        sample_FID = df_keys['FID'].unique()\n",
    "        del(df_keys)\n",
    "        self.df_keys = None\n",
    "        \n",
    "        # Функция для формирования полного пути файла семпла\n",
    "        sample_file_path = lambda s: self.PATH_TO_DATA + 'SAMPLE/' + s[:-4] + '_SAMPLE' + '.csv'\n",
    "        \n",
    "        # Создание папки для сохранения файлов\n",
    "        if not os.path.exists(self.PATH_TO_DATA + 'SAMPLE/'):\n",
    "            os.makedirs(self.PATH_TO_DATA + 'SAMPLE/')\n",
    "        \n",
    "        # Копирование таблицы ACCOUNT            \n",
    "        self.print_log('ACCOUNT Выборка ключей для загрузки', level=0, timestamp=True)\n",
    "        account_skip_rows = self.account_keys[~self.account_keys['FID'].isin(sample_FID)].index\n",
    "\n",
    "        self.print_log('ACCOUNT Загрузка данных', level=0, timestamp=True)\n",
    "        db_account = pd.read_csv(self.PATH_TO_DATA + self.account_csv_file_name,\n",
    "                                 encoding='windows-1251',\n",
    "                                 sep=';',\n",
    "                                 quotechar = '\"',\n",
    "                                 names=self.account_cols,\n",
    "                                 skiprows=account_skip_rows)\n",
    "        \n",
    "        self.print_log('ACCOUNT Cохранение сэмпла данных', level=0, timestamp=True)        \n",
    "        db_account.to_csv(sample_file_path(self.account_csv_file_name),\n",
    "                          encoding='windows-1251',\n",
    "                          sep=';',\n",
    "                          quotechar = '\"',\n",
    "                          header=False,\n",
    "                          index=False)\n",
    "        del(db_account)\n",
    "        \n",
    "        \n",
    "        # Копирование таблицы INFORMATION                \n",
    "        self.print_log('INFORMATION Выборка ключей для загрузки', level=0, timestamp=True)\n",
    "        info_skip_rows = self.info_keys[~self.info_keys['FID'].isin(sample_FID)].index\n",
    "\n",
    "        self.print_log('INFORMATION Загрузка данных', level=0, timestamp=True)\n",
    "        db_info = pd.read_csv(self.PATH_TO_DATA + self.information_csv_file_name,\n",
    "                              encoding='windows-1251',\n",
    "                              sep=';',\n",
    "                              quotechar = '\"',\n",
    "                              names=self.info_cols,\n",
    "                              skiprows=info_skip_rows)\n",
    "        \n",
    "        self.print_log('INFORMATION Cохранение сэмпла данных', level=0, timestamp=True)        \n",
    "        db_info.to_csv(sample_file_path(self.information_csv_file_name),\n",
    "                       encoding='windows-1251',\n",
    "                       sep=';',\n",
    "                       quotechar = '\"',\n",
    "                       header=False,\n",
    "                       index=False)\n",
    "        del(db_info)\n",
    "        \n",
    "        \n",
    "        # Копирование таблицы ADDRESS        \n",
    "        self.print_log('ADDRESS Загрузка данных', level=0, timestamp=True)\n",
    "        db_addr = pd.read_csv(self.PATH_TO_DATA + self.address_csv_file_name,\n",
    "                              encoding='windows-1251',\n",
    "                              sep=';',\n",
    "                              quotechar = '\"',\n",
    "                              names=self.addr_cols)            \n",
    "        \n",
    "        self.print_log('ADDRESS Выборка данных', level=0, timestamp=True)\n",
    "        db_addr = db_addr[db_addr['FID'].isin(sample_FID)]\n",
    "        \n",
    "        self.print_log('ADDRESS Cохранение сэмпла данных', level=0, timestamp=True)\n",
    "        db_addr.to_csv(sample_file_path(self.address_csv_file_name),\n",
    "                       encoding='windows-1251',\n",
    "                       sep=';',\n",
    "                       quotechar = '\"',\n",
    "                       header=False,\n",
    "                       index=False)        \n",
    "        del(db_addr)\n",
    "        \n",
    "        \n",
    "        # Копирование таблицы NAME\n",
    "        self.print_log('NAME Загрузка таблицы', level=0, timestamp=True)\n",
    "        db_names = pd.read_csv(self.PATH_TO_DATA + self.name_csv_file_name,\n",
    "                               names=self.name_cols,\n",
    "                               encoding='windows-1251',\n",
    "                               sep=';',\n",
    "                               quotechar = '\"')\n",
    "        \n",
    "        self.print_log('NAME Выборка данных', level=0, timestamp=True)\n",
    "        db_names = db_names[db_names['FID'].isin(sample_FID)]\n",
    "        \n",
    "        self.print_log('NAME Cохранение сэмпла данных', level=0, timestamp=True)           \n",
    "        db_names.to_csv(sample_file_path(self.name_csv_file_name),\n",
    "                        encoding='windows-1251',\n",
    "                        sep=';',\n",
    "                        quotechar = '\"',\n",
    "                        header=False,\n",
    "                        index=False)\n",
    "        del(db_names)\n",
    "        \n",
    "        \n",
    "        # Копирование таблицы CBRATES\n",
    "        copyfile(self.PATH_TO_DATA + self.cbrates_csv_file_name, sample_file_path(self.cbrates_csv_file_name))\n",
    "        \n",
    "        get_sample_data_result = (self.acct_type_list,\n",
    "                                  self.period_dict,\n",
    "                                  self.PATH_TO_DATA + 'SAMPLE/',\n",
    "                                  self.account_csv_file_name[:-4] + '_SAMPLE' + '.csv',\n",
    "                                  self.information_csv_file_name[:-4] + '_SAMPLE' + '.csv',\n",
    "                                  self.name_csv_file_name[:-4] + '_SAMPLE' + '.csv',\n",
    "                                  self.address_csv_file_name[:-4] + '_SAMPLE' + '.csv',\n",
    "                                  self.cbrates_csv_file_name[:-4] + '_SAMPLE' + '.csv')\n",
    "        \n",
    "        return get_sample_data_result\n",
    "    \n",
    "    # Формирование списка целевых FID\n",
    "    def get_df_keys(self, start_date, finish_date, portion=1):\n",
    "        \n",
    "        self.print_log('ACCOUNT Сбор FID (' + start_date + ' - ' + finish_date + ')', level=1, timestamp=True)\n",
    "        \n",
    "        start_date_int = int(start_date[:4] + start_date[5:7] + start_date[8:])\n",
    "        finish_date_int = int(finish_date[:4] + finish_date[5:7] + finish_date[8:])\n",
    "        \n",
    "        self.df_keys = self.account_keys[(self.account_keys['OPENED_DT'] >= start_date_int) &\n",
    "                                         (self.account_keys['OPENED_DT'] <= finish_date_int) &\n",
    "                                         (self.account_keys['OWNER_INDIC'].isin([1, 4])) &\n",
    "                                         (self.account_keys['ACCT_TYPE'].isin(self.acct_type_list))]        \n",
    "        \n",
    "        if portion < 1:\n",
    "            self.df_keys = self.df_keys.sample(int(self.df_keys.shape[0] * portion), replace=False, random_state=42)\n",
    "\n",
    "    \n",
    "    # Загрузка ключей Account    \n",
    "    def load_account_keys(self):\n",
    "        if str(type(self.account_keys)) == \"<class 'NoneType'>\":\n",
    "            self.print_log('ACCOUNT Загрузка ключей таблицы', level=0, timestamp=True)\n",
    "            self.account_keys = pd.read_csv(self.PATH_TO_DATA + self.account_csv_file_name,\n",
    "                                            encoding='windows-1251',\n",
    "                                            sep=';',\n",
    "                                            quotechar = '\"',\n",
    "                                            names=self.account_cols,\n",
    "                                            usecols=['FID', 'OPENED_DT', 'OWNER_INDIC', 'ACCT_TYPE'])\n",
    "    \n",
    "    \n",
    "    # Загрузка ключей Information    \n",
    "    def laod_info_keys(self):\n",
    "        # Загрузка ключей Information        \n",
    "        if str(type(self.info_keys)) == \"<class 'NoneType'>\":        \n",
    "            self.print_log('INFORMATION Загрузка ключей таблицы', level=0, timestamp=True)\n",
    "            self.info_keys = pd.read_csv(self.PATH_TO_DATA + self.information_csv_file_name,\n",
    "                                         encoding='windows-1251',\n",
    "                                         sep=';',\n",
    "                                         quotechar = '\"',\n",
    "                                         names=self.info_cols,\n",
    "                                         usecols=['FID'])\n",
    "     \n",
    "    \n",
    "    # Загрузка и обработка Name   \n",
    "    def process_db_names (self):\n",
    "\n",
    "        if str(type(self.db_names)) == \"<class 'NoneType'>\":\n",
    "            self.print_log('NAME Загрузка таблицы', level=0, timestamp=True)\n",
    "            db_names = pd.read_csv(self.PATH_TO_DATA + self.name_csv_file_name,\n",
    "                                   names=self.name_cols,\n",
    "                                   encoding='windows-1251',\n",
    "                                   sep=';',\n",
    "                                   quotechar = '\"',\n",
    "                                   converters={'LAST_UPDATED_DT':lambda s: s[:10]})\n",
    "\n",
    "\n",
    "            self.print_log('NAME Предобработка таблицы', level=0, timestamp=True)\n",
    "            db_names['LAST_UPDATED_DT'] = pd.to_datetime(db_names['LAST_UPDATED_DT'], errors='coerce')\n",
    "            db_names['FILE_SINCE_DT'] = pd.to_datetime(db_names['FILE_SINCE_DT'], format='%Y%m%d', errors='coerce')        \n",
    "            db_names['BIRTH_DT'] = pd.to_datetime(db_names['BIRTH_DT'], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "            # Удаление данных где неадекватные даты\n",
    "            db_names = db_names[~db_names['LAST_UPDATED_DT'].isnull()]\n",
    "            db_names = db_names[~db_names['FILE_SINCE_DT'].isnull()]        \n",
    "            db_names = db_names[~db_names['BIRTH_DT'].isnull()]\n",
    "\n",
    "            get_gender = lambda x: 1 if (str(x)[-2:] in ['НА','ЗЫ', 'на', 'зы']) else (0 if (str(x)[-2:] in ['ИЧ','ЛЫ', 'ич', 'лы']) else None)\n",
    "            db_names['GENDER'] = db_names['MIDDLE'].map(get_gender)    \n",
    "            \n",
    "            self.db_names = db_names\n",
    "\n",
    "    \n",
    "    # Загрузка и обработка CBRates \n",
    "    def process_db_cbrates (self):\n",
    "        if str(type(self.db_cbrates)) == \"<class 'NoneType'>\":\n",
    "            self.print_log('CBRATES Загрузка таблицы', level=0, timestamp=True)\n",
    "            db_cbrates = pd.read_csv(self.PATH_TO_DATA + self.cbrates_csv_file_name,\n",
    "                                     sep=';',\n",
    "                                     quotechar = \"'\",\n",
    "                                     decimal=\",\",\n",
    "                                     index_col='ID')\n",
    "\n",
    "            self.print_log('CBRATES Предобработка таблицы', level=0, timestamp=True)\n",
    "\n",
    "            # Удаление лишних валют из таблицы валют\n",
    "            #db_cbrates = db_cbrates.loc[db_cbrates['CODE'].isin(db_account['CURRENCY_CODE'].value_counts().index)]\n",
    "\n",
    "            # Расчет реального курса валюты (с учетом номинала)\n",
    "            db_cbrates['CURRENCY_RATE'] = db_cbrates['RATE'] / db_cbrates['NOMINAL']\n",
    "            db_cbrates['CURRENCY_CODE'] = db_cbrates['CODE'] \n",
    "\n",
    "            db_cbrates.drop(columns=['NOMINAL', 'RATE', 'CODE'], inplace=True)\n",
    "\n",
    "            # Добавление месяца и года курса\n",
    "            db_cbrates['DATE'] = pd.to_datetime(db_cbrates['DATE'], dayfirst=True)\n",
    "            db_cbrates['MONTH'] = db_cbrates['DATE'].dt.month\n",
    "            db_cbrates['YEAR'] = db_cbrates['DATE'].dt.year\n",
    "\n",
    "            # Групировка курсов по месяцам\n",
    "            db_cbrates = db_cbrates.groupby(by=['CURRENCY_CODE', 'YEAR', 'MONTH']).agg({'CURRENCY_RATE':np.mean})\n",
    "            db_cbrates = db_cbrates.reset_index().sort_values(by=['YEAR', 'MONTH', 'CURRENCY_CODE'])\n",
    "\n",
    "            # Добавление строк с курсами на все года с 1996-2005 (добавляется самый ранний известнрый курс)\n",
    "            for year in range(1996,2005):\n",
    "                for month in range(1,13):\n",
    "                    for curr in db_cbrates['CURRENCY_CODE'].unique():\n",
    "                        db_cbrates.loc[db_cbrates.shape[0]] = [curr, year, month, db_cbrates.loc[db_cbrates['CURRENCY_CODE']==curr,'CURRENCY_RATE'].iloc[0]]\n",
    "\n",
    "            # Добавление курса рубля к рублю\n",
    "            for year in range(1996,2025):\n",
    "                for month in range(1,13):\n",
    "                    db_cbrates.loc[db_cbrates.shape[0]] = ['RUB', year, month, 1]\n",
    "\n",
    "            db_cbrates = db_cbrates[['YEAR', 'MONTH', 'CURRENCY_CODE', 'CURRENCY_RATE']].sort_values(by=['YEAR', 'MONTH', 'CURRENCY_CODE'])\n",
    "            db_cbrates.index = np.arange(db_cbrates.shape[0])\n",
    "\n",
    "            self.db_cbrates = db_cbrates\n",
    "    \n",
    "    \n",
    "    # Загрузка и обработка Address \n",
    "    def process_db_addr (self):\n",
    "        \n",
    "        if str(type(self.db_addr)) == \"<class 'NoneType'>\":\n",
    "        \n",
    "            self.print_log('ADDRESS Загрузка таблицы', level=0, timestamp=True)\n",
    "            db_addr = pd.read_csv(self.PATH_TO_DATA + self.address_csv_file_name,\n",
    "                                  encoding='windows-1251',\n",
    "                                  sep=';',\n",
    "                                  quotechar = '\"',\n",
    "                                  names=self.addr_cols)\n",
    "\n",
    "            self.print_log('ADDRESS Предобработка данных', level=0, timestamp=True)\n",
    "\n",
    "            # Удаление типов несоответствующих 1 и 2\n",
    "            db_addr = db_addr.loc[db_addr['ADDR_REL_TYP_CDE'].isin([1, 2, '1', '2'])]\n",
    "\n",
    "            # Удаление пустых значений\n",
    "            db_addr = db_addr[~(db_addr['PROV']=='  ')]\n",
    "            db_addr = db_addr[~db_addr['PROV'].isnull()]\n",
    "\n",
    "            # Преобразование типов\n",
    "            db_addr['LAST_UPDATED_DT'] = pd.to_datetime(db_addr['LAST_UPDATED_DT'].map(lambda s:s[:10]), errors='coerce')\n",
    "            db_addr['FILE_SINCE_DT'] = pd.to_datetime(db_addr['FILE_SINCE_DT'], format='%Y%m%d', errors='coerce')\n",
    "            db_addr['ADDR_REL_TYP_CDE'] = db_addr['ADDR_REL_TYP_CDE'].astype('int32')\n",
    "\n",
    "            # Удаление данных где неадекватные даты\n",
    "            db_addr = db_addr[~db_addr['LAST_UPDATED_DT'].isnull()]\n",
    "            db_addr = db_addr[~db_addr['FILE_SINCE_DT'].isnull()]            \n",
    "\n",
    "            # Отсечение дуюлирующих строк\n",
    "            db_addr = db_addr.groupby(by=['FID', 'PROV','ADDR_REL_TYP_CDE']).agg({'FILE_SINCE_DT':min, 'LAST_UPDATED_DT':max}).reset_index()\n",
    "\n",
    "            self.db_addr = db_addr\n",
    "   \n",
    "\n",
    "    # Загрузка и предобработа данных таблицы ACCOUNT\n",
    "    def process_db_account (self, start_date, finish_date):\n",
    "\n",
    "        self.print_log('ACCOUNT Выборка ключей для загрузки', level=1, timestamp=True)\n",
    "        account_skip_rows = self.account_keys[~self.account_keys['FID'].isin(self.df_keys['FID'])].index\n",
    "\n",
    "        self.print_log('ACCOUNT Загрузка данных', level=1, timestamp=True)\n",
    "        db_account = pd.read_csv(self.PATH_TO_DATA + self.account_csv_file_name,\n",
    "                                 encoding='windows-1251',\n",
    "                                 sep=';',\n",
    "                                 quotechar = '\"',\n",
    "                                 names=self.account_cols,\n",
    "                                 skiprows=account_skip_rows)        \n",
    "\n",
    "        self.print_log('ACCOUNT Предобработка данных', level=1, timestamp=True)\n",
    "        # Удаление записей в которых пустые значение ACCT_TYPE, PAYMT_PAT,CREDIT_LIMIT, ACCT_RTE_CDE, OPENED_DT\n",
    "        db_account = db_account.loc[~db_account['ACCT_TYPE'].isnull()]\n",
    "        db_account = db_account.loc[~db_account['PAYMT_PAT'].isnull()]\n",
    "        db_account = db_account.loc[~db_account['CREDIT_LIMIT'].isnull()]\n",
    "        db_account = db_account.loc[~db_account['ACCT_RTE_CDE'].isnull()]\n",
    "\n",
    "        # Удаление FID по OWNER_INDIC не равен 1 или 4 \n",
    "        db_account = db_account[db_account['OWNER_INDIC'].isin([1, 4])]\n",
    "\n",
    "        # Заполнение пропусков\n",
    "        db_account['AMT_PAST_DUE'].fillna(0, inplace=True)\n",
    "\n",
    "        # Преобразование типов\n",
    "        db_account['FID'] = db_account['FID'].astype('int')\n",
    "        db_account['OWNER_INDIC'] = db_account['OWNER_INDIC'].astype('int')\n",
    "        db_account['ACCT_RTE_CDE'] = db_account['ACCT_RTE_CDE'].astype('int')\n",
    "        db_account['SERIAL_NUM'] = db_account['SERIAL_NUM'].astype('int')\n",
    "        db_account['CREDIT_LIMIT'] =db_account['CREDIT_LIMIT'].astype('int64')\n",
    "        db_account['AMT_PAST_DUE'] = db_account['AMT_PAST_DUE'].astype('int64')\n",
    "        db_account['ACCT_TYPE'] = db_account['ACCT_TYPE'].astype('int')\n",
    "\n",
    "        # удаление днных по нерелевантным тимпам кредитов \n",
    "        db_account = db_account[db_account['ACCT_TYPE'].isin([1,4,6,7,9,13,16,17,18])]\n",
    "\n",
    "        # Удаление FID которых нет в таблице db_names\n",
    "        db_account = db_account.loc[db_account['FID'].isin(self.db_names['FID'])]\n",
    "\n",
    "        #Удаление FID по которым колв-о кредитов больше 100 \n",
    "        num=100\n",
    "        db_account = db_account[~db_account['FID'].isin(db_account['FID'].value_counts()[db_account['FID'].value_counts() > num].index)]\n",
    "\n",
    "        #Даты\n",
    "        db_account['ACCT_RTE_DTE'] = pd.to_datetime(db_account['ACCT_RTE_DTE'], format='%Y%m%d', errors='coerce')\n",
    "        \n",
    "        db_account['CLOSED_DT'] = pd.to_datetime(db_account['CLOSED_DT'], format='%Y%m%d', errors='coerce')\n",
    "        db_account['OPENED_DT'] = pd.to_datetime(db_account['OPENED_DT'], format='%Y%m%d', errors='coerce')\n",
    "        db_account['REPORTING_DT'] = pd.to_datetime(db_account['REPORTING_DT'], format='%Y%m%d', errors='coerce')\n",
    "        db_account['PAYMT_PAT_START_DT'] = pd.to_datetime(db_account['PAYMT_PAT_START_DT'], format='%Y%m%d', errors='coerce')\n",
    "        db_account['PAYT_DUE_DTE'] = pd.to_datetime(db_account['PAYT_DUE_DTE'], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "        # Удаление данных где неадекватные даты\n",
    "        db_account = db_account[~db_account['ACCT_RTE_DTE'].isnull()]\n",
    "        db_account = db_account[~db_account['OPENED_DT'].isnull()]\n",
    "        db_account = db_account[~db_account['PAYMT_PAT_START_DT'].isnull()]\n",
    "        #db_account = db_account[~db_account['PAYT_DUE_DTE'].isnull()]\n",
    "        #db_account = db_account[~db_account['REPORTING_DT'].isnull()]        \n",
    "        \n",
    "        # Добавление месяца и года открытия кредита\n",
    "        db_account['OPENED_DT_WEEKDAY'] = db_account['OPENED_DT'].dt.weekday\n",
    "        db_account['OPENED_DT_DAY'] = db_account['OPENED_DT'].dt.day\n",
    "        db_account['OPENED_DT_MONTH'] = db_account['OPENED_DT'].dt.month\n",
    "        db_account['OPENED_DT_YEAR'] = db_account['OPENED_DT'].dt.year\n",
    "\n",
    "\n",
    "        # преобразование MEMBER_CODE\n",
    "        db_account['MEMBER_CODE'] = db_account['MEMBER_CODE'].map(lambda x: x[:6])    \n",
    "\n",
    "        #Добавление курса валют в db_account и расчет CREDIT_LIMIT_RUB\n",
    "        db_account = pd.merge(db_account, \n",
    "                              self.db_cbrates, \n",
    "                              how='left', \n",
    "                              left_on=['CURRENCY_CODE', 'OPENED_DT_YEAR', 'OPENED_DT_MONTH'], \n",
    "                              right_on=['CURRENCY_CODE', 'YEAR', 'MONTH'])\n",
    "\n",
    "        db_account.drop(columns=['YEAR', 'MONTH', 'OPENED_DT_YEAR'], inplace=True)\n",
    "        db_account['CREDIT_LIMIT_RUB'] = db_account['CREDIT_LIMIT'] * db_account['CURRENCY_RATE']\n",
    "        db_account['AMT_PAST_DUE_RUB'] = db_account['AMT_PAST_DUE'] * db_account['CURRENCY_RATE'] \n",
    "        \n",
    "        self.db_account = db_account\n",
    "\n",
    "        self.print_log('Формирование датасета для сбора агргатов', level=1, timestamp=True)\n",
    "        self.df = self.db_account[(self.db_account['OPENED_DT']>=start_date) &\n",
    "                                  (self.db_account['OPENED_DT']<=finish_date) &\n",
    "                                  (self.db_account['ACCT_TYPE'].isin(self.acct_type_list))].copy()\n",
    "        \n",
    "        \n",
    "    # Предобработка данных таблицы INFORMATION\n",
    "    def process_db_info (self):\n",
    "\n",
    "        self.print_log('INFORMATION Выборка ключей для загрузки', level=1, timestamp=True)\n",
    "        info_skip_rows = self.info_keys[~self.info_keys['FID'].isin(self.df_keys['FID'])].index\n",
    "\n",
    "        self.print_log('INFORMATION Загрузка данных', level=1, timestamp=True)          \n",
    "        db_info = pd.read_csv(PATH_TO_DATA + self.information_csv_file_name,\n",
    "                              encoding='windows-1251',\n",
    "                              sep=';',\n",
    "                              quotechar = '\"',\n",
    "                              names=self.info_cols,\n",
    "                              skiprows=info_skip_rows)\n",
    "\n",
    "        self.print_log('INFORMATION Предобработка данных', level=1, timestamp=True)    \n",
    "        db_info['REJECTED_AMT'].fillna(0, inplace=True)\n",
    "\n",
    "        # Удаление строк где не указан тип кредита\n",
    "        db_info = db_info.loc[~db_info['LOAN_TYPE'].isnull()]\n",
    "\n",
    "        # Удаление FID которых нет TYPE_FLAG <> 1\n",
    "        db_info = db_info[db_info['TYPE_FLAG']==1]\n",
    "\n",
    "        # Преобразование типов\n",
    "        db_info['APP_DATE'] = pd.to_datetime(db_info['APP_DATE'], format='%Y%m%d', errors='coerce')\n",
    "        db_info['REJECTION_DTE'] = pd.to_datetime(db_info['REJECTION_DTE'], format='%Y%m%d', errors='coerce')\n",
    "        \n",
    "        db_info['REJECTED_AMT'] = db_info['REJECTED_AMT'].astype('int64')\n",
    "        db_info['CREDITOR_TYPE'] = db_info['CREDITOR_TYPE'].astype('int32')\n",
    "        db_info['TYPE_FLAG'] = db_info['TYPE_FLAG'].astype('int32')\n",
    "        db_info['LOAN_TYPE'] = db_info['LOAN_TYPE'].astype('int32')\n",
    "        \n",
    "        # преобразование MEMBER_CODE\n",
    "        db_info['MEMBER_CODE'] = db_info['MEMBER_CODE'].map(lambda x: x[:6])    \n",
    "\n",
    "        # Удаление данных где неадекватные даты\n",
    "        db_info = db_info[~db_info['APP_DATE'].isnull()]    \n",
    "\n",
    "        # Замена пустых значений валюты на RUB (REJECTED_AMT - в этих случаях равен 0) \n",
    "        db_info['REJ_AMT_CUR'].loc[db_info['REJ_AMT_CUR'].isin(['   ', 'RU ', 'РУБ', 'RUR'])] = 'RUB'\n",
    "\n",
    "        #Перерасчет суммы отказа в рубли в таблице db_info\n",
    "        db_info['YEAR'] = db_info['APP_DATE'].dt.year\n",
    "        db_info['MONTH'] = db_info['APP_DATE'].dt.month\n",
    "\n",
    "        db_info = pd.merge(db_info, \n",
    "                           self.db_cbrates, \n",
    "                           how='left', \n",
    "                           left_on=['REJ_AMT_CUR', 'YEAR', 'MONTH'], \n",
    "                           right_on=['CURRENCY_CODE', 'YEAR', 'MONTH'])\n",
    "\n",
    "        db_info['REJECTED_AMT_RUB'] = (db_info['REJECTED_AMT'] * db_info['CURRENCY_RATE'])\n",
    "        db_info.drop(columns=['REJECTED_AMT', 'CURRENCY_CODE','CURRENCY_RATE', 'YEAR', 'MONTH'], inplace=True)\n",
    "\n",
    "        self.db_info = db_info\n",
    "    \n",
    "    \n",
    "    # Формирование датасета для сбора агрегатов по отказникам\n",
    "    def keep_rejects_only (self):\n",
    "        \n",
    "        self.print_log('Фильтрация данных по отказникам', level=1, timestamp=True)\n",
    "        \n",
    "        db_info_rej = self.db_info[self.db_info['FLAG_OF_APPROVAL'] != 'Y']\n",
    "        db_info_rej = db_info_rej[db_info_rej['REJECTED_AMT_RUB']>0]\n",
    "        db_info_rej = db_info_rej[~db_info_rej['REJECTION_DTE'].isnull()]\n",
    "        db_info_rej['REJECT_MEMBER_CODE'] = db_info_rej['MEMBER_CODE']\n",
    "        db_info_rej['REJECT_LOAN_TYPE'] = db_info_rej['LOAN_TYPE']\n",
    "        db_info_rej['REJECT_DTE'] = db_info_rej['REJECTION_DTE']\n",
    "        db_info_rej['REJECT_REASON'] = db_info_rej['REJECTION_REASON']\n",
    "        db_info_rej['REJECT_AMT_RUB'] = db_info_rej['REJECTED_AMT_RUB']\n",
    "                \n",
    "        db_info_rej = db_info_rej[['FID', 'REJECT_MEMBER_CODE', 'REJECT_DTE', 'REJECT_LOAN_TYPE', 'REJECT_REASON', 'REJECT_AMT_RUB']]\n",
    "        \n",
    "        df_tmp = pd.merge(self.df[['FID', 'SERIAL_NUM', 'OPENED_DT', 'ACCT_TYPE']],\n",
    "                          db_info_rej,\n",
    "                          how='inner',\n",
    "                          on=['FID'],\n",
    "                          suffixes= ('', '_REJECT'))\n",
    "        \n",
    "        del(db_info_rej)\n",
    "        \n",
    "        df_tmp['REJECT_DAYS_GAP'] = (df_tmp['OPENED_DT'] - df_tmp['REJECT_DTE']).dt.days \n",
    "        df_tmp = df_tmp[df_tmp['REJECT_DAYS_GAP'] >= 0]\n",
    "        df_tmp = df_tmp[df_tmp['REJECT_DAYS_GAP'] <= 90]\n",
    "        \n",
    "        loan_type_30d = [201, 202, 203, 204, 301, 302, 303, 304, 305, 306, 401, 402, 403, 404, 405, 406, 407, 408]\n",
    "        df_tmp = df_tmp[((df_tmp['REJECT_DAYS_GAP'] <= 90) & (df_tmp['REJECT_LOAN_TYPE'].isin([101, 102])) & (df_tmp['ACCT_TYPE'] == 1)) |\n",
    "                        ((df_tmp['REJECT_DAYS_GAP'] <= 90) & (df_tmp['REJECT_LOAN_TYPE'].isin([501])) & (df_tmp['ACCT_TYPE'] == 6)) | \n",
    "                        ((df_tmp['REJECT_DAYS_GAP'] <= 30) & (df_tmp['REJECT_LOAN_TYPE'].isin(loan_type_30d)) & (df_tmp['ACCT_TYPE'].isin([16, 7, 9])))]\n",
    "        \n",
    "        df_tmp.drop_duplicates(inplace=True)\n",
    "\n",
    "        self.df = self.df[self.df['SERIAL_NUM'].isin(df_tmp['SERIAL_NUM'])]\n",
    "        self.df_rejects = df_tmp[['SERIAL_NUM', 'REJECT_MEMBER_CODE', 'REJECT_DTE', 'REJECT_LOAN_TYPE', 'REJECT_REASON', 'REJECT_AMT_RUB']].copy()\n",
    "        del(df_tmp)\n",
    "    \n",
    "    \n",
    "    # Функция добавление агрегатов REGION_REG и REGION_PR\n",
    "    def agg_db_address(self):\n",
    "        \n",
    "        self.print_log('ADDRESS Сбор агрегатов', level=1, timestamp=True)\n",
    "        df_tmp = pd.merge(self.df[['SERIAL_NUM', 'FID', 'OPENED_DT']],\n",
    "                          self.db_addr,\n",
    "                          how='left',\n",
    "                          on=['FID'],\n",
    "                          suffixes= ('', '_ADR'))\n",
    "        df_tmp = df_tmp.loc[df_tmp['OPENED_DT'] >= df_tmp['FILE_SINCE_DT']]\n",
    "        df_tmp.sort_values(by=['SERIAL_NUM', 'FILE_SINCE_DT'], ascending=[True, False], inplace=True)\n",
    "        df_tmp.drop_duplicates(subset=['SERIAL_NUM', 'ADDR_REL_TYP_CDE'], keep='first', inplace=True)\n",
    "\n",
    "        df_tmp['REGION_REG'] = 0\n",
    "        df_tmp['REGION_PR'] = 0\n",
    "        df_tmp['REGION_REG'].loc[df_tmp['ADDR_REL_TYP_CDE']==1] = df_tmp['PROV']\n",
    "        df_tmp['REGION_PR'].loc[df_tmp['ADDR_REL_TYP_CDE']==2] = df_tmp['PROV']\n",
    "\n",
    "        df_tmp['REGION_REG']  = df_tmp['REGION_REG'].astype('int')\n",
    "        df_tmp['REGION_PR']  = df_tmp['REGION_PR'].astype('int')\n",
    "\n",
    "        df_tmp = df_tmp.groupby(by=['SERIAL_NUM']).agg({'REGION_REG':np.sum, 'REGION_PR':np.sum})\n",
    "\n",
    "        self.df['REGION_PR'] = self.df['SERIAL_NUM'].map(df_tmp['REGION_PR'].loc[df_tmp['REGION_PR']!=0].to_dict())\n",
    "        self.df['REGION_REG'] = self.df['SERIAL_NUM'].map(df_tmp['REGION_REG'].loc[df_tmp['REGION_REG']!=0].to_dict())\n",
    "        \n",
    "        del(df_tmp)\n",
    "    \n",
    "    \n",
    "    # Функция добавление агрегатов FID_DATE и FID_DAYS\n",
    "    def agg_db_names(self):\n",
    "        \n",
    "        self.print_log('NAME Сбор агрегатов', level=1, timestamp=True)\n",
    "        \n",
    "        self.db_names.sort_values(by=['FID', 'FILE_SINCE_DT'], ascending=[True,True], inplace=True)\n",
    "        df_tmp = self.db_names.drop_duplicates(subset=['FID'], keep='first')\n",
    "        df_tmp = df_tmp[df_tmp['FID'].isin(self.df['FID'])]\n",
    "\n",
    "        self.df['FID_DATE'] = self.df['FID'].map(df_tmp.set_index('FID')['FILE_SINCE_DT'].to_dict())\n",
    "        self.df['FID_DAYS'] = (self.df['OPENED_DT'] - self.df['FID_DATE']).dt.days\n",
    "\n",
    "\n",
    "        # Добавление AGE\n",
    "        df_tmp = pd.merge(self.df[['SERIAL_NUM', 'FID', 'OPENED_DT']],\n",
    "                          self.db_names,\n",
    "                          how='left',\n",
    "                          on=['FID'],\n",
    "                          suffixes= ('', '_NAME'))\n",
    "\n",
    "        df_tmp = df_tmp.loc[df_tmp['OPENED_DT'] >= df_tmp['FILE_SINCE_DT']]\n",
    "        df_tmp.sort_values(by=['SERIAL_NUM', 'FILE_SINCE_DT'], ascending=[True, False], inplace=True)\n",
    "        df_tmp.drop_duplicates(subset=['SERIAL_NUM'], keep='first', inplace=True)\n",
    "\n",
    "        df_tmp['AGE'] = round((df_tmp['OPENED_DT'] - df_tmp['BIRTH_DT']).dt.days/365,0).astype('int')\n",
    "\n",
    "        df_tmp.set_index('SERIAL_NUM', inplace=True)\n",
    "        self.df['AGE'] = self.df['SERIAL_NUM'].map(df_tmp['AGE'].to_dict())\n",
    "\n",
    "        # Добавление GENDER\n",
    "        df_tmp = pd.merge(self.df[['SERIAL_NUM', 'FID', 'OPENED_DT']],\n",
    "                          self.db_names,\n",
    "                          how='left',\n",
    "                          on=['FID'],\n",
    "                          suffixes= ('', '_NAME'))\n",
    "\n",
    "        df_tmp = df_tmp[~df_tmp['GENDER'].isnull()]\n",
    "        df_tmp = df_tmp[df_tmp['OPENED_DT'] >= df_tmp['FILE_SINCE_DT']]\n",
    "        df_tmp.sort_values(by=['SERIAL_NUM', 'FILE_SINCE_DT'], ascending=[True, False], inplace=True)\n",
    "        df_tmp.drop_duplicates(subset=['SERIAL_NUM'], keep='first', inplace=True)\n",
    "        df_tmp.set_index('SERIAL_NUM', inplace=True)\n",
    "\n",
    "        self.df['GENDER'] = self.df['SERIAL_NUM'].map(df_tmp['GENDER'].to_dict())\n",
    "        \n",
    "        del(df_tmp)\n",
    "    \n",
    "    \n",
    "    # Функция добавление агрегатов FID_DATE и FID_DAYS  \n",
    "    def agg_db_info(self):\n",
    "        \n",
    "        self.print_log('INFORMATION Сбор агрегатов', level=1, timestamp=True)\n",
    "        df_tmp = pd.merge(self.df[['SERIAL_NUM', 'FID', 'OPENED_DT']],\n",
    "                          self.db_info,\n",
    "                          how='inner',\n",
    "                          on=['FID'],\n",
    "                          suffixes= ('', '_INFO'))\n",
    "\n",
    "        df_tmp = df_tmp[df_tmp['OPENED_DT'] > df_tmp['APP_DATE']]\n",
    "\n",
    "        df_tmp.sort_values(by = ['FID', 'SERIAL_NUM', 'APP_DATE'], inplace=True)\n",
    "\n",
    "        df_tmp['DAYS_GAP'] = (df_tmp['OPENED_DT'] - df_tmp['APP_DATE']).dt.days.astype('int')\n",
    "\n",
    "        df_tmp['REQUESTS_1M_CNT'] = (df_tmp['DAYS_GAP'] <= 30)\n",
    "        df_tmp['REQUESTS_3M_CNT'] = (df_tmp['DAYS_GAP'] <= 90)\n",
    "        df_tmp['REQUESTS_6M_CNT'] = (df_tmp['DAYS_GAP'] <= 180)\n",
    "        df_tmp['REQUESTS_12M_CNT'] = (df_tmp['DAYS_GAP'] <= 360)\n",
    "        df_tmp['REQUESTS_24M_CNT'] = (df_tmp['DAYS_GAP'] <= 720)\n",
    "        df_tmp['REQUESTS_36M_CNT'] = (df_tmp['DAYS_GAP'] <= 1080)\n",
    "\n",
    "        LOAN_TYPE_LIST =  [101, 102, 201, 202, 203, 204, 301, 302, 303, 304, 305, 306, 401, 402, 403, 404, 405, 406, 407, 408, 451, 501, 601, 999]\n",
    "        for LOAN_TYPE in LOAN_TYPE_LIST:\n",
    "            df_tmp['REQUESTS_{}_1M_CNT'.format(LOAN_TYPE)] = ((df_tmp['DAYS_GAP'] <= 30) & (df_tmp['LOAN_TYPE']==LOAN_TYPE)).astype('bool')\n",
    "            df_tmp['REQUESTS_{}_3M_CNT'.format(LOAN_TYPE)] = ((df_tmp['DAYS_GAP'] <= 90) & (df_tmp['LOAN_TYPE']==LOAN_TYPE)).astype('bool')\n",
    "\n",
    "        df_tmp['REQUESTS_CT1_1M_CNT'] = ((df_tmp['DAYS_GAP'] <= 30) & (df_tmp['CREDITOR_TYPE']==1)).astype('bool')\n",
    "        df_tmp['REQUESTS_CT2_1M_CNT'] = ((df_tmp['DAYS_GAP'] <= 30) & (df_tmp['CREDITOR_TYPE']==2)).astype('bool')\n",
    "        df_tmp['REQUESTS_CT3_1M_CNT'] = ((df_tmp['DAYS_GAP'] <= 30) & (df_tmp['CREDITOR_TYPE']==3)).astype('bool')\n",
    "        df_tmp['REQUESTS_CT4_1M_CNT'] = ((df_tmp['DAYS_GAP'] <= 30) & (df_tmp['CREDITOR_TYPE']==4)).astype('bool')\n",
    "        df_tmp['REQUESTS_CT1_3M_CNT'] = ((df_tmp['DAYS_GAP'] <= 90) & (df_tmp['CREDITOR_TYPE']==1)).astype('bool')\n",
    "        df_tmp['REQUESTS_CT2_3M_CNT'] = ((df_tmp['DAYS_GAP'] <= 90) & (df_tmp['CREDITOR_TYPE']==2)).astype('bool')\n",
    "        df_tmp['REQUESTS_CT3_3M_CNT'] = ((df_tmp['DAYS_GAP'] <= 90) & (df_tmp['CREDITOR_TYPE']==3)).astype('bool')\n",
    "        df_tmp['REQUESTS_CT4_3M_CNT'] = ((df_tmp['DAYS_GAP'] <= 90) & (df_tmp['CREDITOR_TYPE']==4)).astype('bool')\n",
    "\n",
    "        cols = df_tmp.loc[:,'REJECTED_AMT_RUB':].columns.drop('DAYS_GAP')\n",
    "\n",
    "        # Сохранение проверочных даннык\n",
    "        self.df_test_info = df_tmp[df_tmp['FID'].isin(self.df_test_FID)].copy()\n",
    "        \n",
    "        df_tmp = df_tmp.groupby(by='SERIAL_NUM')\n",
    "        for col in cols:\n",
    "            self.df[col] = self.df['SERIAL_NUM'].map(df_tmp.agg({col:np.sum})[col].to_dict()).fillna(0).astype('int') \n",
    "        \n",
    "\n",
    "        \n",
    "        del(df_tmp)\n",
    "    \n",
    "    \n",
    "    # Сбор агрегатов из таблицы ACCOUNT\n",
    "    def agg_db_account(self):\n",
    "        \n",
    "        self.print_log('ACCOUNT Сбор агрегатов', level=1, timestamp=True)\n",
    "        \n",
    "        # Слияние\n",
    "        df_tmp = pd.merge(self.df[['SERIAL_NUM', 'FID', 'OPENED_DT', 'MEMBER_CODE']],\n",
    "                          self.db_account,\n",
    "                          how='inner',\n",
    "                          on=['FID'],\n",
    "                          suffixes= ('', '_ACC'))\n",
    "\n",
    "        df_tmp = df_tmp[df_tmp['OPENED_DT'] > df_tmp['OPENED_DT_ACC']]\n",
    "        df_tmp.sort_values(by = ['FID', 'SERIAL_NUM', 'OPENED_DT_ACC'], inplace=True)\n",
    "\n",
    "\n",
    "        df_tmp['DAYS_GAP'] = (df_tmp['OPENED_DT'] - df_tmp['OPENED_DT_ACC']).dt.days.astype('int')\n",
    "\n",
    "        df_tmp['REPEAT'] = (df_tmp['MEMBER_CODE'] == df_tmp['MEMBER_CODE_ACC'])\n",
    "        df_tmp['REPEAT_CNT'] = (df_tmp['MEMBER_CODE'] == df_tmp['MEMBER_CODE_ACC'])\n",
    "        df_tmp['MEMBER_CODE_CNT'] = df_tmp['MEMBER_CODE_ACC']    \n",
    "\n",
    "        df_tmp['CREDIT_ALL_CNT'] = True\n",
    "        df_tmp['CREDIT_CLOSED_CNT'] = (df_tmp['ACCT_RTE_DTE'] < df_tmp['OPENED_DT']) & (df_tmp['ACCT_RTE_CDE']!=0)\n",
    "        df_tmp['CREDIT_CURR_OPEN_CNT'] = ~df_tmp['CREDIT_CLOSED_CNT'] \n",
    "        df_tmp['CREDIT_CLOSED_BEFORE_CNT'] = df_tmp['CREDIT_CLOSED_CNT'] & (df_tmp['ACCT_RTE_DTE'] <= df_tmp['PAYT_DUE_DTE']) & (df_tmp['ACCT_RTE_CDE'] == 13)\n",
    "\n",
    "        df_tmp['CREDIT_ALL_SUM'] = df_tmp['CREDIT_LIMIT_RUB']\n",
    "        df_tmp['CREDIT_SUM_AVG'] = df_tmp['CREDIT_LIMIT_RUB']\n",
    "        df_tmp['CREDIT_SUM_AVG'][df_tmp['CREDIT_LIMIT_RUB'] == 0] = None\n",
    "\n",
    "        df_tmp['CREDIT_CLOSED_SUM_AVG'] = None\n",
    "        df_tmp['CREDIT_CLOSED_SUM_AVG'].loc[df_tmp['CREDIT_CLOSED_CNT'] & (df_tmp['CREDIT_LIMIT_RUB'] > 0)] = df_tmp['CREDIT_LIMIT_RUB']\n",
    "        df_tmp['CREDIT_CLOSED_SUM_AVG'] = df_tmp['CREDIT_CLOSED_SUM_AVG'].astype('float')\n",
    "\n",
    "        df_tmp['CREDIT_TYPE_CNT'] = df_tmp['ACCT_TYPE']    \n",
    "\n",
    "        df_tmp['OPEN_CREDIT_1M_CNT'] = (df_tmp['DAYS_GAP'] <= 30) & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "        df_tmp['OPEN_CREDIT_3M_CNT'] = (df_tmp['DAYS_GAP'] <= 90) & (df_tmp['CREDIT_LIMIT_RUB'] > 0) \n",
    "        df_tmp['OPEN_CREDIT_6M_CNT'] = (df_tmp['DAYS_GAP'] <= 180) & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "        df_tmp['OPEN_CREDIT_12M_CNT'] = (df_tmp['DAYS_GAP'] <= 360) & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "        df_tmp['OPEN_CREDIT_24M_CNT'] = (df_tmp['DAYS_GAP'] <= 720) & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "        df_tmp['OPEN_CREDIT_36M_CNT'] = (df_tmp['DAYS_GAP'] <= 1080) & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "\n",
    "        df_tmp['CLOSED_CREDIT_1M_CNT'] = ((df_tmp['OPENED_DT'] - df_tmp['ACCT_RTE_DTE']).dt.days <= 30) & df_tmp['CREDIT_CLOSED_CNT'] & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "        df_tmp['CLOSED_CREDIT_3M_CNT'] = ((df_tmp['OPENED_DT'] - df_tmp['ACCT_RTE_DTE']).dt.days <= 90) & df_tmp['CREDIT_CLOSED_CNT'] & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "        df_tmp['CLOSED_CREDIT_6M_CNT'] = ((df_tmp['OPENED_DT'] - df_tmp['ACCT_RTE_DTE']).dt.days <= 180) & df_tmp['CREDIT_CLOSED_CNT'] & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "        df_tmp['CLOSED_CREDIT_12M_CNT'] = ((df_tmp['OPENED_DT'] - df_tmp['ACCT_RTE_DTE']).dt.days <= 360) & df_tmp['CREDIT_CLOSED_CNT'] & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "        df_tmp['CLOSED_CREDIT_24M_CNT'] = ((df_tmp['OPENED_DT'] - df_tmp['ACCT_RTE_DTE']).dt.days <= 720) & df_tmp['CREDIT_CLOSED_CNT'] & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "        df_tmp['CLOSED_CREDIT_36M_CNT'] = ((df_tmp['OPENED_DT'] - df_tmp['ACCT_RTE_DTE']).dt.days <= 1080) & df_tmp['CREDIT_CLOSED_CNT'] & (df_tmp['CREDIT_LIMIT_RUB'] > 0)    \n",
    "\n",
    "        df_tmp['CREDIT_DAYS_AVG'] = None\n",
    "        df_tmp['CREDIT_DAYS_AVG'].loc[df_tmp['CREDIT_CLOSED_CNT'] & (df_tmp['CREDIT_LIMIT_RUB'] > 0)] = (df_tmp['ACCT_RTE_DTE']-df_tmp['OPENED_DT_ACC']).dt.days\n",
    "        df_tmp['CREDIT_DAYS_AVG'] = df_tmp['CREDIT_DAYS_AVG'].astype('float')\n",
    "        df_tmp['CREDIT_DAYS_MAX'] = df_tmp['CREDIT_DAYS_AVG']\n",
    "        df_tmp['CREDIT_DAYS_MIN'] = df_tmp['CREDIT_DAYS_AVG']\n",
    "\n",
    "        df_tmp['LAST_OPEN_CREDIT_DAYS'] = None\n",
    "        df_tmp['LAST_OPEN_CREDIT_DAYS'][df_tmp['CREDIT_LIMIT_RUB'] > 0] = df_tmp['DAYS_GAP']\n",
    "        df_tmp['LAST_OPEN_CREDIT_DAYS'] = df_tmp['LAST_OPEN_CREDIT_DAYS'].astype('float')\n",
    "        df_tmp['FIRST_OPEN_CREDIT_DAYS'] = df_tmp['LAST_OPEN_CREDIT_DAYS']\n",
    "\n",
    "        df_tmp['LAST_CARD_USAGE_PERIOD_DAYS'] = None\n",
    "        df_tmp['LAST_CARD_USAGE_PERIOD_DAYS'].loc[(df_tmp['ACCT_TYPE'] == 7) & (df_tmp['CREDIT_LIMIT_RUB'] > 0)] = df_tmp['DAYS_GAP'] \n",
    "        df_tmp['LAST_CARD_USAGE_PERIOD_DAYS'] = df_tmp['LAST_CARD_USAGE_PERIOD_DAYS'].astype('float')\n",
    "\n",
    "        df_tmp['MICRO_CREDIT_ALL_CNT'] = (df_tmp['ACCT_TYPE'] == 16) & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "        df_tmp['MICRO_CREDIT_12M_CNT'] = (df_tmp['DAYS_GAP'] <= 360) & (df_tmp['ACCT_TYPE'] == 16) & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "        df_tmp['MICRO_CREDIT_24M_CNT'] = (df_tmp['DAYS_GAP'] <= 720) & (df_tmp['ACCT_TYPE'] == 16) & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "        df_tmp['MICRO_CREDIT_36M_CNT'] = (df_tmp['DAYS_GAP'] <= 1080) & (df_tmp['ACCT_TYPE'] == 16) & (df_tmp['CREDIT_LIMIT_RUB'] > 0)\n",
    "\n",
    "        df_tmp['PAYMTPOS'] = (df_tmp['PAYMT_PAT_START_DT'].dt.year - df_tmp['OPENED_DT'].dt.year)*12 + (df_tmp['PAYMT_PAT_START_DT'].dt.month - df_tmp['OPENED_DT'].dt.month)\n",
    "        df_tmp['PAYMTPOS_LAST_12M'] = 12\n",
    "        df_tmp['PAYMTPOS_LAST_12M'][df_tmp['PAYMTPOS'] < 0] = df_tmp['PAYMTPOS_LAST_12M'] + df_tmp['PAYMTPOS']\n",
    "        df_tmp['PAYMTPOS_LAST_12M'][df_tmp['PAYMTPOS_LAST_12M'] < 0] = 0\n",
    "        df_tmp['PAYMTPOS'][df_tmp['PAYMTPOS'] < 0] = 0\n",
    "\n",
    "        df_tmp['zip_pat'] = list(zip(df_tmp['PAYMT_PAT'], df_tmp['PAYMTPOS']))\n",
    "\n",
    "        self.print_log('Расчет PAYMT_PAT_RETRO', level=2, timestamp=True)         \n",
    "        df_tmp['PAYMT_PAT_RETRO'] = df_tmp['zip_pat'].map(lambda zip_pat: zip_pat[0][zip_pat[1]:])\n",
    "\n",
    "        df_tmp.drop(columns='zip_pat', inplace=True)\n",
    "\n",
    "        df_tmp['zip_pat_12m'] = list(zip(df_tmp['PAYMT_PAT_RETRO'], df_tmp['PAYMTPOS_LAST_12M']))\n",
    "\n",
    "        self.print_log('Расчет PAYMT_PAT_RETRO_LAST_12M', level=2, timestamp=True)         \n",
    "        df_tmp['PAYMT_PAT_RETRO_LAST_12M'] = df_tmp['zip_pat_12m'].map(lambda zip_pat: zip_pat[0][:zip_pat[1]])\n",
    "\n",
    "        df_tmp.drop(columns='zip_pat_12m', inplace=True)\n",
    "\n",
    "        df_tmp['BAD_CREDIT_ALL_CNT'] = (df_tmp['ACCT_RTE_DTE'] < df_tmp['OPENED_DT']) & (df_tmp['ACCT_RTE_CDE'].isin([21, 61, 90, 95, 96])) & (df_tmp['CREDIT_LIMIT_RUB'] > 500)\n",
    "        df_tmp['BAD_CREDIT_12M_CNT'] = ((df_tmp['OPENED_DT'] - df_tmp['ACCT_RTE_DTE']).dt.days <360) & (df_tmp['ACCT_RTE_DTE'] < df_tmp['OPENED_DT']) & (df_tmp['ACCT_RTE_CDE'].isin([21, 61, 90, 95, 96])) & (df_tmp['CREDIT_LIMIT_RUB'] > 500)\n",
    "        df_tmp['BAD_CREDIT_24M_CNT'] = ((df_tmp['OPENED_DT'] - df_tmp['ACCT_RTE_DTE']).dt.days <720) & (df_tmp['ACCT_RTE_DTE'] < df_tmp['OPENED_DT']) & (df_tmp['ACCT_RTE_CDE'].isin([21, 61, 90, 95, 96])) & (df_tmp['CREDIT_LIMIT_RUB'] > 500)\n",
    "        df_tmp['BAD_CREDIT_36M_CNT'] = ((df_tmp['OPENED_DT'] - df_tmp['ACCT_RTE_DTE']).dt.days <1080) & (df_tmp['ACCT_RTE_DTE'] < df_tmp['OPENED_DT']) & (df_tmp['ACCT_RTE_CDE'].isin([21, 61, 90, 95, 96])) & (df_tmp['CREDIT_LIMIT_RUB'] > 500)\n",
    "\n",
    "        self.print_log('Расчет PMT_ALL_CNT', level=2, timestamp=True)        \n",
    "        df_tmp['PMT_ALL_CNT'] = df_tmp['PAYMT_PAT_RETRO'].map(len)\n",
    "\n",
    "        self.print_log('Расчет GOOD_PMT_ALL_CNT', level=2, timestamp=True)    \n",
    "        df_tmp['GOOD_PMT_ALL_CNT'] = df_tmp['PAYMT_PAT_RETRO'].map(lambda pat: np.sum([pat.count(s) for s in '1']))\n",
    "\n",
    "        self.print_log('Расчет BAD_PMT_ALL_CNT', level=2, timestamp=True)   \n",
    "        df_tmp['BAD_PMT_ALL_CNT'] = df_tmp['PAYMT_PAT_RETRO'].map(lambda pat: np.sum([pat.count(s) for s in 'A2345789']))\n",
    "\n",
    "        self.print_log('Расчет OVERDUE_CREDIT_ALL_CNT', level=2, timestamp=True)   \n",
    "        df_tmp['OVERDUE_CREDIT_ALL_CNT'] = (df_tmp['PAYMT_PAT_RETRO'].map(lambda pat: np.sum([pat.count(s) for s in 'A2345789'])) > 0)\n",
    "\n",
    "        self.print_log('Расчет OVERDUE_CREDIT_ALL_30_CNT', level=2, timestamp=True)   \n",
    "        df_tmp['OVERDUE_CREDIT_ALL_30_CNT'] = (df_tmp['PAYMT_PAT_RETRO'].map(lambda pat: np.sum([pat.count(s) for s in '2345789'])) > 0)\n",
    "\n",
    "        self.print_log('Расчет OVERDUE_CREDIT_ALL_60_CNT', level=2, timestamp=True)   \n",
    "        df_tmp['OVERDUE_CREDIT_ALL_60_CNT'] = (df_tmp['PAYMT_PAT_RETRO'].map(lambda pat: np.sum([pat.count(s) for s in '345789'])) > 0)\n",
    "\n",
    "        self.print_log('Расчет OVERDUE_CREDIT_ALL_90_CNT', level=2, timestamp=True)   \n",
    "        df_tmp['OVERDUE_CREDIT_ALL_90_CNT'] = (df_tmp['PAYMT_PAT_RETRO'].map(lambda pat: np.sum([pat.count(s) for s in '45789'])) > 0)\n",
    "\n",
    "        self.print_log('Расчет PMT_12M_CNT', level=2, timestamp=True)   \n",
    "        df_tmp['PMT_12M_CNT'] = df_tmp['PAYMT_PAT_RETRO_LAST_12M'].map(len)\n",
    "\n",
    "        self.print_log('Расчет GOOD_PMT_12M_CNT', level=2, timestamp=True)   \n",
    "        df_tmp['GOOD_PMT_12M_CNT'] = df_tmp['PAYMT_PAT_RETRO_LAST_12M'].map(lambda pat: np.sum([pat.count(s) for s in '1']))\n",
    "\n",
    "        self.print_log('Расчет BAD_PMT_12M_CNT', level=2, timestamp=True)   \n",
    "        df_tmp['BAD_PMT_12M_CNT'] = df_tmp['PAYMT_PAT_RETRO_LAST_12M'].map(lambda pat: np.sum([pat.count(s) for s in 'A2345789']))\n",
    "\n",
    "        self.print_log('Расчет OVERDUE_CREDIT_12M_CNT', level=2, timestamp=True)   \n",
    "        df_tmp['OVERDUE_CREDIT_12M_CNT'] = (df_tmp['PAYMT_PAT_RETRO_LAST_12M'].map(lambda pat: np.sum([pat.count(s) for s in 'A2345789'])) > 0)\n",
    "\n",
    "        self.print_log('Расчет OVERDUE_CREDIT_12M_30_CNT', level=2, timestamp=True)   \n",
    "        df_tmp['OVERDUE_CREDIT_12M_30_CNT'] = (df_tmp['PAYMT_PAT_RETRO_LAST_12M'].map(lambda pat: np.sum([pat.count(s) for s in '2345789'])) > 0)\n",
    "\n",
    "        self.print_log('Расчет OVERDUE_CREDIT_12M_60_CNT', level=2, timestamp=True)   \n",
    "        df_tmp['OVERDUE_CREDIT_12M_60_CNT'] = (df_tmp['PAYMT_PAT_RETRO_LAST_12M'].map(lambda pat: np.sum([pat.count(s) for s in '345789'])) > 0)\n",
    "\n",
    "        self.print_log('Расчет OVERDUE_CREDIT_12M_90_CNT', level=2, timestamp=True)   \n",
    "        df_tmp['OVERDUE_CREDIT_12M_90_CNT'] = (df_tmp['PAYMT_PAT_RETRO_LAST_12M'].map(lambda pat: np.sum([pat.count(s) for s in '45789'])) > 0)\n",
    "\n",
    "        self.print_log('Расчет OVERDUE_CREDIT_CURR_CNT', level=2, timestamp=True)\n",
    "        df_tmp['OVERDUE_CREDIT_CURR_CNT'] = (df_tmp['PAYMT_PAT_RETRO'].map(lambda pat: np.sum([pat.count(s) for s in 'A2345789'])) > 0) & df_tmp['CREDIT_CURR_OPEN_CNT']\n",
    "\n",
    "        df_tmp['OVERDUE_DURATION_DAYS_MAX'] = 0\n",
    "        df_tmp['OVERDUE_DURATION_DAYS_MAX'].loc[(df_tmp['ACCT_RTE_DTE'] < df_tmp['OPENED_DT']) & (df_tmp['ACCT_RTE_CDE'] == 52) & (df_tmp['CREDIT_LIMIT_RUB'] > 500)] = (df_tmp['OPENED_DT'] - df_tmp['ACCT_RTE_DTE']).dt.days\n",
    "        df_tmp['OVERDUE_DURATION_DAYS_MAX'] = df_tmp['OVERDUE_DURATION_DAYS_MAX'].astype('int')\n",
    "\n",
    "        df_tmp['GOOD_CREDIT_CLOSED_CNT'] = (df_tmp['BAD_PMT_ALL_CNT'] == 0) & (df_tmp['CLOSED_DT'] < df_tmp['OPENED_DT'])    \n",
    "\n",
    "        # Группировка и перенос данных\n",
    "        cols = list(df_tmp.loc[:,'DAYS_GAP':].columns.drop(['DAYS_GAP', 'PAYMTPOS' ,'PAYMTPOS_LAST_12M', 'PAYMT_PAT_RETRO', 'PAYMT_PAT_RETRO_LAST_12M']))\n",
    "        df_tmp_agg = df_tmp.groupby(by='SERIAL_NUM')\n",
    "\n",
    "        for col in cols:\n",
    "            if col in ['CREDIT_DAYS_MAX', 'FIRST_OPEN_CREDIT_DAYS', 'OVERDUE_DURATION_DAYS_MAX']:\n",
    "                agg_func = np.max\n",
    "\n",
    "            elif col in ['CREDIT_DAYS_MIN', 'LAST_OPEN_CREDIT_DAYS', 'LAST_CARD_USAGE_PERIOD_DAYS']:\n",
    "                agg_func = np.min\n",
    "\n",
    "            elif col in ['CREDIT_DAYS_AVG', 'CREDIT_SUM_AVG', 'CREDIT_CLOSED_SUM_AVG']:\n",
    "                agg_func = np.mean\n",
    "\n",
    "            elif col in ['REPEAT']:\n",
    "                agg_func = lambda x: int(np.sum(x) > 0)\n",
    "\n",
    "            elif col in ['CREDIT_TYPE_CNT', 'MEMBER_CODE_CNT']:\n",
    "                agg_func = lambda x: len(np.unique(x))\n",
    "\n",
    "            else:\n",
    "                agg_func = np.sum\n",
    "            \n",
    "            self.print_log('Агрегация ' + col, level=2, timestamp=True)\n",
    "            self.df[col] = self.df['SERIAL_NUM'].map(df_tmp_agg.agg({col:agg_func})[col].to_dict())\n",
    "        \n",
    "        # Сохранение проверочных даннык\n",
    "        self.df_test_account = df_tmp[df_tmp['FID'].isin(self.df_test_FID)].copy()\n",
    "        \n",
    "        del(df_tmp)\n",
    "\n",
    "    \n",
    "    # Расчет флагов и дополнительных агрегатов\n",
    "    def flag_calculation(self):\n",
    "        \n",
    "        self.print_log('Расчет флагов и дополнительных агрегатов', level=1, timestamp=True)\n",
    "        self.df['CREDIT_PERIOD_DAYS'] = (self.df['PAYT_DUE_DTE'] - self.df['OPENED_DT']).dt.days\n",
    "\n",
    "        self.df['CREDIT_WITH_DUE_RATE'] = self.df['OVERDUE_CREDIT_ALL_CNT'] / self.df['CREDIT_ALL_CNT'] * 100\n",
    "        self.df['OVERDUE_CREDIT_CURR_RATE'] = self.df['OVERDUE_CREDIT_CURR_CNT'] / self.df['CREDIT_CURR_OPEN_CNT'] * 100\n",
    "\n",
    "        self.df['BAD_PMT_ALL_RATE'] = self.df['BAD_PMT_ALL_CNT'] / self.df['PMT_ALL_CNT']\n",
    "        self.df['BAD_PMT_12M_RATE'] = self.df['BAD_PMT_12M_CNT'] / self.df['PMT_12M_CNT']\n",
    "\n",
    "        self.df['CREDIT_HISTORY'] = (~self.df['REPEAT'].isnull()).astype('int')\n",
    "\n",
    "        #Заполнение нулей и преобразование типов\n",
    "        for col in self.df.loc[:,'REPEAT':'BAD_PMT_12M_RATE'].columns:\n",
    "            self.df[col].fillna(0, inplace=True)\n",
    "            if str(self.df[col].dtype)[:5] == 'float' and np.sum(self.df[col]) == np.sum(self.df[col].astype(int)):\n",
    "                self.df[col] = self.df[col].astype('int')\n",
    "        \n",
    "        self.df['REPEAT'] = self.df['REPEAT'].astype('int')\n",
    "        self.df['CREDIT_DAYS_AVG'] = self.df['CREDIT_DAYS_AVG'].astype('int')\n",
    "        self.df['CREDIT_SUM_AVG'] = self.df['CREDIT_SUM_AVG'].astype('int')\n",
    "        self.df['CREDIT_ALL_SUM'] = self.df['CREDIT_ALL_SUM'].astype('int')        \n",
    "        self.df['CREDIT_CLOSED_SUM_AVG'] = self.df['CREDIT_CLOSED_SUM_AVG'].astype('int')\n",
    "\n",
    "        #Расчет Флагов\n",
    "        self.print_log('Расчет 90_24_MOB', level=2, timestamp=True)  \n",
    "        self.df['90_24_MOB']  = self.df['PAYMT_PAT'].map(lambda pat: np.sum([pat[-(24 if (pat[-1] =='0') else 23):][0].count(s) for s in '4589'])>0).astype('int')\n",
    "\n",
    "        self.print_log('Расчет 90_24_EVER', level=2, timestamp=True)      \n",
    "        self.df['90_24_EVER'] = self.df['PAYMT_PAT'].map(lambda pat: np.sum([pat[-(24 if (pat[-1] =='0') else 23):].count(s) for s in '4589'])>0).astype('int')\n",
    "\n",
    "        self.print_log('Расчет 90_12_MOB', level=2, timestamp=True)    \n",
    "        self.df['90_12_MOB']  = self.df['PAYMT_PAT'].map(lambda pat: np.sum([pat[-(12 if (pat[-1] =='0') else 11):][0].count(s) for s in '4589'])>0).astype('int')\n",
    "\n",
    "        self.print_log('Расчет 0_12_EVER', level=2, timestamp=True)    \n",
    "        self.df['90_12_EVER'] = self.df['PAYMT_PAT'].map(lambda pat: np.sum([pat[-(12 if (pat[-1] =='0') else 11):].count(s) for s in '4589'])>0).astype('int')\n",
    "\n",
    "        self.print_log('Расчет 60_6_MOB', level=2, timestamp=True)       \n",
    "        self.df['60_6_MOB']  = self.df['PAYMT_PAT'].map(lambda pat: np.sum([pat[-(6 if (pat[-1] =='0') else 5):][0].count(s) for s in '34589'])>0).astype('int')\n",
    "\n",
    "        self.print_log('Расчет 60_6_EVER', level=2, timestamp=True)           \n",
    "        self.df['60_6_EVER'] = self.df['PAYMT_PAT'].map(lambda pat: np.sum([pat[-(6 if (pat[-1] =='0') else 5):].count(s) for s in '34589'])>0).astype('int')\n",
    "\n",
    "        self.print_log('Расчет 60_12_MOB', level=2, timestamp=True)    \n",
    "        self.df['60_12_MOB']  = self.df['PAYMT_PAT'].map(lambda pat: np.sum([pat[-(12 if (pat[-1] =='0') else 11):][0].count(s) for s in '34589'])>0).astype('int')\n",
    "\n",
    "        self.print_log('Расчет 60_12_EVER', level=2, timestamp=True)    \n",
    "        self.df['60_12_EVER'] = self.df['PAYMT_PAT'].map(lambda pat: np.sum([pat[-(12 if (pat[-1] =='0') else 11):].count(s) for s in '34589'])>0).astype('int')\n",
    "\n",
    "        self.print_log('Расчет 30_3_MOB', level=2, timestamp=True) \n",
    "        self.df['30_3_MOB']  = self.df['PAYMT_PAT'].map(lambda pat: np.sum([pat[-(3 if (pat[-1] =='0') else 2):][0].count(s) for s in '234589'])>0).astype('int')\n",
    "\n",
    "        self.print_log('Расчет 30_3_EVER', level=2, timestamp=True)      \n",
    "        self.df['30_3_EVER'] = self.df['PAYMT_PAT'].map(lambda pat: np.sum([pat[-(3 if (pat[-1] =='0') else 2):].count(s) for s in '234589'])>0).astype('int')\n",
    "\n",
    "        self.print_log('Расчет FPD', level=2, timestamp=True) \n",
    "        self.df['FPD'] = self.df['PAYMT_PAT'].map(lambda pat: np.sum([pat.rstrip('0')[-1:].count(s) for s in 'A2345789']) > 0).astype('int')\n",
    "\n",
    "        self.print_log('Расчет SPD', level=2, timestamp=True) \n",
    "        self.df['SPD'] = self.df['PAYMT_PAT'].map(lambda pat: np.sum([pat.rstrip('0')[-2:].count(s) for s in 'A2345789']) > 0).astype('int')\n",
    "\n",
    "        self.print_log('Расчет TPD', level=2, timestamp=True)   \n",
    "        self.df['TPD'] = self.df['PAYMT_PAT'].map(lambda pat: np.sum([pat.rstrip('0')[-3:].count(s) for s in 'A2345789']) > 0).astype('int')\n",
    "\n",
    "        # Корректировка флагов в случае если флаг дефолта не вызрел (длинна PAYMT_PAT не меньше периода флага и кредит еще открыт)\n",
    "        self.df['90_24_MOB'][self.df['PAYMT_PAT'].map(lambda pat: len(pat) < (24 if (pat[-1] =='0') else 23)) & (self.df['ACCT_RTE_CDE'] == 0)] = None\n",
    "        self.df['90_24_EVER'][self.df['PAYMT_PAT'].map(lambda pat: len(pat) < (24 if (pat[-1] =='0') else 23)) & (self.df['ACCT_RTE_CDE'] == 0)] = None\n",
    "\n",
    "        self.df['90_12_MOB'][self.df['PAYMT_PAT'].map(lambda pat: len(pat) < (12 if (pat[-1] =='0') else 11)) & (self.df['ACCT_RTE_CDE'] == 0)] = None\n",
    "        self.df['90_12_EVER'][self.df['PAYMT_PAT'].map(lambda pat: len(pat) < (12 if (pat[-1] =='0') else 11)) & (self.df['ACCT_RTE_CDE'] == 0)] = None\n",
    "\n",
    "        self.df['60_12_MOB'][self.df['PAYMT_PAT'].map(lambda pat: len(pat) < (12 if (pat[-1] =='0') else 11)) & (self.df['ACCT_RTE_CDE'] == 0)] = None\n",
    "        self.df['60_12_EVER'][self.df['PAYMT_PAT'].map(lambda pat: len(pat) < (12 if (pat[-1] =='0') else 11)) & (self.df['ACCT_RTE_CDE'] == 0)] = None   \n",
    "\n",
    "        self.df['60_6_MOB'][self.df['PAYMT_PAT'].map(lambda pat: len(pat) < (6 if (pat[-1] =='0') else 5)) & (self.df['ACCT_RTE_CDE'] == 0)] = None\n",
    "        self.df['60_6_EVER'][self.df['PAYMT_PAT'].map(lambda pat: len(pat) < (6 if (pat[-1] =='0') else 5)) & (self.df['ACCT_RTE_CDE'] == 0)] = None\n",
    "\n",
    "        self.df['30_3_MOB'][self.df['PAYMT_PAT'].map(lambda pat: len(pat) < (4 if (pat[-1] =='0') else 3)) & (self.df['ACCT_RTE_CDE'] == 0)] = None\n",
    "        self.df['30_3_EVER'][self.df['PAYMT_PAT'].map(lambda pat: len(pat) < (4 if (pat[-1] =='0') else 3)) & (self.df['ACCT_RTE_CDE'] == 0)] = None\n",
    "\n",
    "        self.df['FPD'][self.df['PAYMT_PAT'].map(lambda pat: len(pat.rstrip('0')[-1:]) < 1)] = None\n",
    "        self.df['SPD'][self.df['PAYMT_PAT'].map(lambda pat: len(pat.rstrip('0')[-2:]) < 2) & (self.df['ACCT_RTE_CDE'] == 0)] = None\n",
    "        self.df['TPD'][self.df['PAYMT_PAT'].map(lambda pat: len(pat.rstrip('0')[-3:]) < 3) & (self.df['ACCT_RTE_CDE'] == 0)] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **СБОР АГРЕГАТОВ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### BANK_90 2017.12-2019.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_dict = {'201902': ['2019-02-01', '2019-02-28'],\n",
    "               '201901': ['2019-01-01', '2019-01-31'],\n",
    "               '201812': ['2018-12-01', '2018-12-31'],\n",
    "               '201811': ['2018-11-01', '2018-11-30'],\n",
    "               '201810': ['2018-10-01', '2018-10-31'],\n",
    "               '201809': ['2018-09-01', '2018-09-30'],\n",
    "               '201808': ['2018-08-01', '2018-08-31'],\n",
    "               '201807': ['2018-07-01', '2018-07-31'],\n",
    "               '201806': ['2018-06-01', '2018-06-30'],\n",
    "               '201805': ['2018-05-01', '2018-05-31'],\n",
    "               '201804': ['2018-04-01', '2018-04-30'],\n",
    "               '201803': ['2018-03-01', '2018-03-31'],\n",
    "               '201802': ['2018-02-01', '2018-02-28'],               \n",
    "               '201801': ['2018-01-01', '2018-01-31'], \n",
    "               '201712': ['2017-12-01', '2017-12-31']}\n",
    "\n",
    "PATH_TO_DATA = 'Z:/ushakov/(PROJECTS)/bank_90/(data)/FID_201712-201902/'\n",
    "\n",
    "account_csv_file_name = 'FID_201712-201902_ACCOUNT.csv'\n",
    "information_csv_file_name = 'FID_201712-201902_INFORMATION.csv'\n",
    "name_csv_file_name = 'FID_201712-201902_NAME.csv'\n",
    "address_csv_file_name = 'FID_201712-201902_ADDRESS.csv'\n",
    "cbrates_csv_file_name = 'CBRATES.csv'\n",
    "\n",
    "bank_90_agg_collector = AggCollector(acct_type_list=[1, 6, 7, 9],\n",
    "                                     period_dict=period_dict,\n",
    "                                     PATH_TO_DATA=PATH_TO_DATA,\n",
    "                                     account_csv_file_name=account_csv_file_name, \n",
    "                                     information_csv_file_name=information_csv_file_name, \n",
    "                                     name_csv_file_name=name_csv_file_name, \n",
    "                                     address_csv_file_name=address_csv_file_name, \n",
    "                                     cbrates_csv_file_name=cbrates_csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сбор агрегатов по всем займам\n",
    "bank_90_agg_collector.collect(check_data_export=False,\n",
    "                              collect_rejects=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "РАСЧЕТ АГРЕГАТОВ\n",
      "\n",
      "ACCOUNT Загрузка ключей таблицы   ....................................   2020-03-16 16:32:23\n",
      "INFORMATION Загрузка ключей таблицы   ................................   2020-03-16 16:40:18\n",
      "ADDRESS Загрузка таблицы   ...........................................   2020-03-16 16:47:50\n",
      "ADDRESS Предобработка данных   .......................................   2020-03-16 17:03:32\n",
      "NAME Загрузка таблицы   ..............................................   2020-03-16 17:26:11\n",
      "NAME Предобработка таблицы   .........................................   2020-03-16 17:27:19\n",
      "CBRATES Загрузка таблицы   ...........................................   2020-03-16 17:29:04\n",
      "CBRATES Предобработка таблицы   ......................................   2020-03-16 17:29:04\n",
      "\n",
      "ПЕРИОД 2019-02-01 - 2019-02-28:\n",
      "    ACCOUNT Сбор FID (2019-02-01 - 2019-02-28)   .....................   2020-03-16 17:29:20\n",
      "    ACCOUNT Выборка ключей для загрузки   ............................   2020-03-16 17:30:40\n",
      "    ACCOUNT Загрузка данных   ........................................   2020-03-16 17:33:24\n",
      "    ACCOUNT Предобработка данных   ...................................   2020-03-16 17:42:45\n",
      "    Формирование датасета для сбора агргатов   .......................   2020-03-16 17:47:20\n",
      "    INFORMATION Выборка ключей для загрузки   ........................   2020-03-16 17:47:24\n",
      "    INFORMATION Загрузка данных   ....................................   2020-03-16 17:54:27\n"
     ]
    }
   ],
   "source": [
    "# Сбор агрегатов по отказным займам\n",
    "bank_90_agg_collector.collect(periods_to_collect_list=['201902', '201901', '201812'],\n",
    "                              check_data_export=False,\n",
    "                              collect_rejects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_90_agg_collector.get_sample_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BANK_90 SAMPLE 2017.12-2019.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "period_dict = {'201902': ['2019-02-01', '2019-02-28'],\n",
    "               '201901': ['2019-01-01', '2019-01-31'],\n",
    "               '201812': ['2018-12-01', '2018-12-31'],\n",
    "               '201811': ['2018-11-01', '2018-11-30'],\n",
    "               '201810': ['2018-10-01', '2018-10-31'],\n",
    "               '201809': ['2018-09-01', '2018-09-30'],\n",
    "               '201808': ['2018-08-01', '2018-08-31'],\n",
    "               '201807': ['2018-07-01', '2018-07-31'],\n",
    "               '201806': ['2018-06-01', '2018-06-30'],\n",
    "               '201805': ['2018-05-01', '2018-05-31'],\n",
    "               '201804': ['2018-04-01', '2018-04-30'],\n",
    "               '201803': ['2018-03-01', '2018-03-31'],\n",
    "               '201802': ['2018-02-01', '2018-02-28'],               \n",
    "               '201801': ['2018-01-01', '2018-01-31'], \n",
    "               '201712': ['2017-12-01', '2017-12-31']}\n",
    "\n",
    "PATH_TO_DATA = 'Z:/ushakov/(PROJECTS)/bank_90/(data)/FID_201712-201902/SAMPLE/'\n",
    "\n",
    "account_csv_file_name = 'FID_201712-201902_ACCOUNT_SAMPLE.csv'\n",
    "information_csv_file_name = 'FID_201712-201902_INFORMATION_SAMPLE.csv'\n",
    "name_csv_file_name = 'FID_201712-201902_NAME_SAMPLE.csv'\n",
    "address_csv_file_name = 'FID_201712-201902_ADDRESS_SAMPLE.csv'\n",
    "cbrates_csv_file_name = 'CBRATES_SAMPLE.csv'\n",
    "\n",
    "bank_90_sample_agg_collector = AggCollector(acct_type_list=[1, 6, 7, 9],\n",
    "                                             period_dict=period_dict,\n",
    "                                             PATH_TO_DATA=PATH_TO_DATA,\n",
    "                                             account_csv_file_name=account_csv_file_name, \n",
    "                                             information_csv_file_name=information_csv_file_name, \n",
    "                                             name_csv_file_name=name_csv_file_name, \n",
    "                                             address_csv_file_name=address_csv_file_name, \n",
    "                                             cbrates_csv_file_name=cbrates_csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сбор агрегатов по всем займам\n",
    "bank_90_sample_agg_collector.collect(check_data_export=False,\n",
    "                                     collect_rejects=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сбор агрегатов по отказным займам\n",
    "bank_90_sample_agg_collector.collect(periods_to_collect_list=['201902', '201901', '201812'],\n",
    "                                     check_data_export=False,\n",
    "                                     collect_rejects=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### MFO 2019.07.01-2019.10.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "period_dict = {'20190701': ['2019-07-01', '2019-07-15'],\n",
    "               '20190716': ['2019-07-16', '2019-07-31'],\n",
    "               '20190801': ['2019-08-01', '2019-08-15'],\n",
    "               '20190816': ['2019-08-16', '2019-08-31'],\n",
    "               '20190901': ['2019-09-01', '2019-09-15'],\n",
    "               '20190916': ['2019-09-16', '2019-09-30'],\n",
    "               '20191001': ['2019-10-01', '2019-10-15'],\n",
    "               '20191016': ['2019-10-16', '2019-10-31']}\n",
    "\n",
    "PATH_TO_DATA = 'Z:/ushakov/(PROJECTS)/MFO/(data)/FID_20190701-20191031/'\n",
    "\n",
    "account_csv_file_name = 'FID_20190701-20191031_ACCOUNT.csv'\n",
    "information_csv_file_name = 'FID_20190701-20191031_INFORMATION.csv'\n",
    "name_csv_file_name = 'FID_20190701-20191031_NAME.csv'\n",
    "address_csv_file_name = 'FID_20190701-20191031_ADDRESS.csv'\n",
    "cbrates_csv_file_name = 'CBRATES.csv'\n",
    "\n",
    "MFO_agg_collector = AggCollector(acct_type_list=[16],\n",
    "                                 period_dict=period_dict,\n",
    "                                 PATH_TO_DATA=PATH_TO_DATA,\n",
    "                                 account_csv_file_name=account_csv_file_name, \n",
    "                                 information_csv_file_name=information_csv_file_name, \n",
    "                                 name_csv_file_name=name_csv_file_name, \n",
    "                                 address_csv_file_name=address_csv_file_name, \n",
    "                                 cbrates_csv_file_name=cbrates_csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MFO_agg_collector.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
